{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Patch-based Transformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from CV.util import imagenet_ind2str\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyper parameter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "transform_origin = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "origin_set = datasets.ImageFolder('./data/ImageNet/val', transform=transform_origin)\n",
    "test_set = datasets.ImageFolder('./data/ImageNet/val', transform=transform_test)\n",
    "origin_loader = DataLoader(origin_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformation methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def shuffler(img):\n",
    "    d = 7\n",
    "    sub_imgs = []\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sub_img = img[i * 224 // d:(i + 1) * 224 // d, j * 224 // d:(j + 1) * 224 // d]\n",
    "            sub_imgs.append(sub_img)\n",
    "    np.random.shuffle(sub_imgs)\n",
    "    new_img = np.vstack([np.hstack([sub_imgs[i] for i in range(d*j, d*(j+1))]) for j in range(d)])\n",
    "    return new_img\n",
    "\n",
    "def rotator(img):\n",
    "    d = 7\n",
    "    sub_imgs = []\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sub_img = img[i * 224 // d:(i + 1) * 224 // d, j * 224 // d:(j + 1) * 224 // d]\n",
    "            sub_imgs.append(sub_img)\n",
    "    sub_imgs = [np.rot90(sub_img) for sub_img in sub_imgs]\n",
    "    new_img = np.vstack([np.hstack([sub_imgs[i] for i in range(d * j, d * (j + 1))]) for j in range(d)])\n",
    "    return new_img\n",
    "\n",
    "def show_img(n, shuffle=False, rotate=False):\n",
    "    for i, data in enumerate(origin_loader):\n",
    "        if i == n:\n",
    "            inputs, labels = data\n",
    "            inputs_np, labels_np = inputs.numpy(), labels.numpy()\n",
    "            inputs_np = np.transpose(inputs_np, (0, 2, 3, 1))[0]\n",
    "            if shuffle:\n",
    "                inputs_np = shuffler(inputs_np)\n",
    "            if rotate:\n",
    "                inputs_np = rotator(inputs_np)\n",
    "            plt.imshow(inputs_np)\n",
    "            plt.title(imagenet_ind2str(int(labels_np)))\n",
    "            plt.show()\n",
    "            break\n",
    "\n",
    "def show_reverse_img(images, labels):\n",
    "    std_array = np.reshape([0.229, 0.224, 0.225], (1, 1, 3))\n",
    "    mean_array = np.reshape([0.485, 0.456, 0.406], (1, 1, 3))\n",
    "    reversed_img = images * std_array + mean_array\n",
    "    plt.imshow(reversed_img)\n",
    "    plt.title(imagenet_ind2str(int(labels)))\n",
    "    plt.show()\n",
    "\n",
    "def cal_dist(tensor1, tensor2):\n",
    "    squared_diff = np.square(tensor1 - tensor2)\n",
    "    sum_squared_diff = np.sum(squared_diff)\n",
    "    distance = np.sqrt(sum_squared_diff)\n",
    "    return distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Class 선언"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class PatchHeatMap(object):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.img_origin = None\n",
    "        self.img_trans = None\n",
    "        self.labels = None\n",
    "        self.tensor_origin = None\n",
    "        self.tensor_trans = None\n",
    "        self.conf_origin = 0\n",
    "        self.conf_trans = 0\n",
    "        self.conf_diff = []\n",
    "        self.list_labels = []\n",
    "\n",
    "    def process_v(self, n, shuffle=False, rotate=False):\n",
    "        self.build_model()\n",
    "        self.extract_tnc(n, shuffle, rotate)\n",
    "        self.visual()\n",
    "\n",
    "    def process_g(self, shuffle=False, rotate=False):\n",
    "        self.build_model()\n",
    "        self.grouping(shuffle, rotate)\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model = timm.models.vit_base_patch16_224(pretrained=True)\n",
    "        print(f'Parameter: {sum(p.numel() for p in self.model.parameters() if p.requires_grad)}')\n",
    "        print(f'Classes: {self.model.num_classes}')\n",
    "        print(f'****** Model Creating Completed. ******\\n')\n",
    "\n",
    "    def extract_tnc(self, n, shuffle, rotate):\n",
    "        self.model.to(device).eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (images, labels) in tqdm(enumerate(test_loader, 0), total=len(test_loader)):\n",
    "                if idx == n:\n",
    "                    images = images.numpy()\n",
    "                    images = np.transpose(images, (0, 2, 3, 1))[0]\n",
    "                    images_t = images\n",
    "                    if shuffle:\n",
    "                        images_t = shuffler(images_t)\n",
    "                    if rotate:\n",
    "                        images_t = rotator(images_t)\n",
    "\n",
    "                    self.img_origin = images\n",
    "                    self.img_trans = images_t\n",
    "                    self.labels = labels\n",
    "\n",
    "                    images = torch.from_numpy(images.transpose((2, 0, 1)).reshape(1, 3, 224, 224)).float()\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs, self.tensor_origin = self.model(images)\n",
    "                    _, pred = torch.max(outputs, 1)\n",
    "                    probs = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
    "                    self.conf_origin = probs[int(labels)].to('cpu')\n",
    "\n",
    "                    images_t = torch.from_numpy(images_t.transpose((2, 0, 1)).reshape(1, 3, 224, 224)).float()\n",
    "                    images_t = images_t.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs, self.tensor_trans = self.model(images_t)\n",
    "                    _, pred = torch.max(outputs, 1)\n",
    "                    probs = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
    "                    self.conf_trans = probs[int(labels)].to('cpu')\n",
    "                    break\n",
    "\n",
    "    def visual(self):\n",
    "        show_reverse_img(self.img_origin, self.labels)\n",
    "        show_reverse_img(self.img_trans, self.labels)\n",
    "        print(f'Label : {imagenet_ind2str(int(self.labels))}')\n",
    "        print(f'Confidence of origin : {float(self.conf_origin):.3f}')\n",
    "        print(f'Confidence of trans : {float(self.conf_trans):.3f}')\n",
    "\n",
    "        np_origin = self.tensor_origin.to('cpu').numpy()\n",
    "        np_origin = np_origin.reshape(197, 768)\n",
    "        np_origin = np.delete(np_origin, 0, axis=0)\n",
    "        np_trans = self.tensor_trans.to('cpu').numpy()\n",
    "        np_trans = np_trans.reshape(197, 768)\n",
    "        np_trans = np.delete(np_trans, 0, axis=0)\n",
    "\n",
    "        dists = [cal_dist(i, j) for i, j in zip(np_origin, np_trans)]\n",
    "        df = np.array(dists).reshape(14, 14)\n",
    "\n",
    "        sns.heatmap(data=df,\n",
    "                    annot=True,\n",
    "                    cmap='Oranges',\n",
    "                    linewidths=.5,\n",
    "                    vmax=50,\n",
    "                    vmin=-0,\n",
    "                    cbar_kws={'shrink': .5})\n",
    "        plt.show()\n",
    "\n",
    "    def grouping(self, shuffle, rotate):\n",
    "        self.model.to(device).eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (images, labels) in tqdm(enumerate(test_loader, 0), total=len(test_loader)):\n",
    "                images = images.numpy()\n",
    "                images = np.transpose(images, (0, 2, 3, 1))[0]\n",
    "                images_t = images\n",
    "                if shuffle:\n",
    "                    images_t = shuffler(images_t)\n",
    "                if rotate:\n",
    "                    images_t = rotator(images_t)\n",
    "\n",
    "                self.img_origin = images\n",
    "                self.img_trans = images_t\n",
    "                self.labels = labels\n",
    "\n",
    "                images = torch.from_numpy(images.transpose((2, 0, 1)).reshape(1, 3, 224, 224)).float()\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs, __ = self.model(images)\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "                probs = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
    "                self.conf_origin = probs[int(labels)].to('cpu')\n",
    "\n",
    "                images_t = torch.from_numpy(images_t.transpose((2, 0, 1)).reshape(1, 3, 224, 224)).float()\n",
    "                images_t = images_t.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs, __ = self.model(images_t)\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "                probs = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
    "                self.conf_trans = probs[int(labels)].to('cpu')\n",
    "\n",
    "                self.conf_diff.append(float(self.conf_origin-self.conf_trans))\n",
    "                self.list_labels.append(int(self.labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 86567656\n",
      "Classes: 1000\n",
      "****** Model Creating Completed. ******\n",
      "\n",
      "[-0.4473997950553894]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "p = PatchHeatMap()\n",
    "p.process_g(shuffle=True)\n",
    "conf_diff = p.conf_diff\n",
    "list_labels = p.list_labels\n",
    "print(len(conf_diff))\n",
    "print(len(list_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
