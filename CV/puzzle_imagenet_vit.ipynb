{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d87b04c5",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21127e7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T06:27:16.393613Z",
     "start_time": "2024-04-17T06:27:12.874904Z"
    }
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from timm.data import create_transform, IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, Mixup\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet50\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from puzzle_res50 import PuzzleCNNCoord\n",
    "from puzzle_vit import PuzzleViT\n",
    "from util.tester import visualDoubleLoss\n",
    "\n",
    "import facebook_vit\n",
    "from mae_util import interpolate_pos_embed, RandomResizedCrop, LARS\n",
    "from timm.models.layers import trunc_normal_\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "gpu_ids = []\n",
    "device_names = []\n",
    "if torch.cuda.is_available():\n",
    "    for gpu_id in range(torch.cuda.device_count()):\n",
    "        gpu_ids += [gpu_id]\n",
    "        device_names += [torch.cuda.get_device_name(gpu_id)]\n",
    "print(gpu_ids)\n",
    "print(device_names)\n",
    "\n",
    "if len(gpu_ids) > 1:\n",
    "    gpu = 'cuda:' + str(gpu_ids[1])  # GPU Number\n",
    "else:\n",
    "    gpu = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ec88d",
   "metadata": {},
   "source": [
    "## Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3bb432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T06:27:16.401497Z",
     "start_time": "2024-04-17T06:27:16.396785Z"
    }
   },
   "outputs": [],
   "source": [
    "device = gpu\n",
    "\n",
    "'''Pre-training'''\n",
    "LEARNING_RATE = 1e-05\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "NUM_WORKERS = 2\n",
    "TASK_NAME = 'puzzle_imagenet_1000'\n",
    "MODEL_NAME = 'vitPreFalse'\n",
    "pre_model_path = f'./save/{TASK_NAME}_{MODEL_NAME}_ep{NUM_EPOCHS}_lr{LEARNING_RATE}_b{BATCH_SIZE}.pt'\n",
    "pre_load_model_path = './save/xxx.pt'\n",
    "pre_reload_model_path = './save/xxx.pt'\n",
    "\n",
    "'''Fine-tuning'''\n",
    "# AUGMENTATION = True\n",
    "# LEARNING_RATE = 2e-02\n",
    "# BATCH_SIZE = 32\n",
    "# NUM_EPOCHS = 100\n",
    "# WARMUP_EPOCHS = 5\n",
    "# NUM_WORKERS = 2\n",
    "# TASK_NAME = 'classification_ImageNet'\n",
    "# fine_load_model_path = './save/puzzle_imagenet_1000_vit_ep20_lr7e-05_b64_c.pt'  # duplicate file\n",
    "# fine_model_path = fine_load_model_path[:-3] + f'___{TASK_NAME}_ep{NUM_EPOCHS}_lr{LEARNING_RATE}_b{BATCH_SIZE}_SGD_aug.pt'\n",
    "# fine_reload_model_path = './save/xxx.pt'\n",
    "\n",
    "'''Linear-probing'''\n",
    "# LEARNING_RATE = 2\n",
    "# BATCH_SIZE = 32\n",
    "# NUM_EPOCHS = 100\n",
    "# WARMUP_EPOCHS = 5\n",
    "# NUM_WORKERS = 2\n",
    "# TASK_NAME = 'linear_ImageNet'\n",
    "# fine_load_model_path = './save/puzzle_imagenet_1000_vit_ep100_lr1e-05_b64_c.pt'  # duplicate file\n",
    "# fine_model_path = fine_load_model_path[:-3] + f'___{TASK_NAME}_ep{NUM_EPOCHS}_lr{LEARNING_RATE}_b{BATCH_SIZE}_SGD.pt'\n",
    "# fine_reload_model_path = './save/xxx.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10322ed9",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84874840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T06:27:21.272172Z",
     "start_time": "2024-04-17T06:27:16.403803Z"
    }
   },
   "outputs": [],
   "source": [
    "'''Pre-training'''\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Pad(padding=3),\n",
    "#     transforms.CenterCrop(30),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5,), (0.5,))\n",
    "# ])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=PIL.Image.BICUBIC),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Pad(padding=(0, 0, 1, 1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "'''Fine-tuning'''\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize(256, interpolation=PIL.Image.BICUBIC),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# if AUGMENTATION:\n",
    "#     transform = create_transform(\n",
    "#         input_size=224,\n",
    "#         is_training=True,\n",
    "#         color_jitter=None,\n",
    "#         auto_augment='rand-m9-mstd0.5-inc1',\n",
    "#         interpolation='bicubic',\n",
    "#         re_prob=0.25,\n",
    "#         re_mode='pixel',\n",
    "#         re_count=1,\n",
    "#         mean=IMAGENET_DEFAULT_MEAN,\n",
    "#         std=IMAGENET_DEFAULT_STD,\n",
    "#     )\n",
    "\n",
    "# mixup_fn = Mixup(\n",
    "#     mixup_alpha=0.8,\n",
    "#     cutmix_alpha=1.0,\n",
    "#     cutmix_minmax=None,\n",
    "#     prob=1.0,\n",
    "#     switch_prob=0.5,\n",
    "#     mode='batch',\n",
    "#     label_smoothing=0.1,\n",
    "#     num_classes=1000\n",
    "# )\n",
    "\n",
    "'''Linear-probing'''\n",
    "# transform = transforms.Compose([\n",
    "#             RandomResizedCrop(224, interpolation=PIL.Image.BICUBIC),\n",
    "#             transforms.RandomHorizontalFlip(),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
    "# )\n",
    "\n",
    "# train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "# val_dataset = Subset(train_dataset, list(range(int(0.2*len(train_dataset)))))\n",
    "# val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "# test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "train_dataset = datasets.ImageFolder('../datasets/ImageNet/train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "val_dataset = Subset(train_dataset, list(range(int(0.01 * len(train_dataset)))))\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "test_dataset = datasets.ImageFolder('../datasets/ImageNet/val', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd71b4",
   "metadata": {},
   "source": [
    "## Pre-training class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee66ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T06:27:21.295741Z",
     "start_time": "2024-04-17T06:27:21.275352Z"
    }
   },
   "outputs": [],
   "source": [
    "class PreTrainer(object):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.epochs = []\n",
    "        self.losses_c = []\n",
    "        self.losses_t = []\n",
    "        self.accuracies = []\n",
    "\n",
    "    def process(self, load=False, reload=False):\n",
    "        self.build_model(load)\n",
    "        self.pretrain_model(reload)\n",
    "        self.save_model()\n",
    "\n",
    "    def build_model(self, load):\n",
    "        self.model = PuzzleViT(size_puzzle=75).to(device)\n",
    "        print(f'Parameter: {sum(p.numel() for p in self.model.parameters() if p.requires_grad)}')\n",
    "        if load:\n",
    "            checkpoint = torch.load(pre_load_model_path)\n",
    "            self.epochs = checkpoint['epochs']\n",
    "            self.model.load_state_dict(checkpoint['model'])\n",
    "            self.losses_c = checkpoint['losses_coord']\n",
    "            self.losses_t = checkpoint['losses_total']\n",
    "            print(f'Parameter: {sum(p.numel() for p in self.model.parameters() if p.requires_grad)}')\n",
    "            print(f'Epoch: {self.epochs[-1]}')\n",
    "            print(f'****** Reset epochs and losses ******')\n",
    "            self.epochs = []\n",
    "            self.losses_c = []\n",
    "            self.losses_t = []\n",
    "\n",
    "    def pretrain_model(self, reload):\n",
    "        model = self.model\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.05)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "        range_epochs = range(NUM_EPOCHS)\n",
    "        if reload:\n",
    "            checkpoint = torch.load(pre_reload_model_path)\n",
    "            self.model.load_state_dict(checkpoint['model'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "            self.epochs = checkpoint['epochs']\n",
    "            self.losses_c = checkpoint['losses_coord']\n",
    "            self.losses_t = checkpoint['losses_total']\n",
    "            self.accuracies = checkpoint['accuracies']\n",
    "            range_epochs = range(self.epochs[-1], NUM_EPOCHS)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range_epochs:\n",
    "            running_loss_c = 0.\n",
    "            running_loss_t = 0.\n",
    "            for batch_idx, (inputs, _) in tqdm(enumerate(train_loader, 0), total=len(train_loader)):\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs, labels, loss_var = model(inputs)\n",
    "                loss_coord = criterion(outputs, labels)\n",
    "                loss = loss_coord + loss_var/1e05\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss_c += loss_coord.item()\n",
    "                running_loss_t += loss.item()\n",
    "\n",
    "                inter = 100\n",
    "                if batch_idx % inter == inter - 1:\n",
    "                    print(f'[Epoch {epoch + 1}] [Batch {batch_idx + 1}] Loss: {running_loss_c / inter:.4f}')\n",
    "                    print(f'[Epoch {epoch + 1}] [Batch {batch_idx + 1}] Total Loss: {running_loss_t / inter:.4f}')\n",
    "                    self.epochs.append(epoch + 1)\n",
    "                    self.losses_c.append(running_loss_c / inter)\n",
    "                    self.losses_t.append(running_loss_t / inter)\n",
    "                    running_loss_c = 0.\n",
    "                    running_loss_t = 0.\n",
    "            scheduler.step()\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "            self.scheduler = scheduler\n",
    "            self.save_model()\n",
    "            visualDoubleLoss(self.losses_c, self.losses_t)\n",
    "            self.val_model(epoch)\n",
    "        print('****** Finished Fine-tuning ******')\n",
    "        self.model = model\n",
    "\n",
    "    def val_model(self, epoch=-1):\n",
    "        model = self.model\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total = 0\n",
    "        diff = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, _) in tqdm(enumerate(val_loader, 0), total=len(val_loader)):\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                outputs, labels, _ = model(inputs)\n",
    "\n",
    "                pred = outputs\n",
    "                total += labels.size(0)\n",
    "                diff += (torch.dist(pred, labels)).sum().item()\n",
    "                pred_ = model.mapping(pred)\n",
    "                labels_ = model.mapping(labels)\n",
    "                correct += (pred_ == labels_).all(dim=2).sum().item()\n",
    "\n",
    "        acc = 100 * correct / (total * labels.size(1))\n",
    "        print(f'[Epoch {epoch + 1}] Avg diff on the test set: {diff / total:.2f}')\n",
    "        print(f'[Epoch {epoch + 1}] Accuracy on the test set: {acc:.2f}%')\n",
    "        torch.set_printoptions(precision=2)\n",
    "        total = labels.size(1)\n",
    "        correct = (pred_[0] == labels_[0]).all(dim=1).sum().item()\n",
    "        print(f'[Sample result]')\n",
    "        print(torch.cat((pred_[0], labels_[0]), dim=1))\n",
    "        print(f'Accuracy: {100 * correct / total:.2f}%')\n",
    "        self.accuracies.append(acc)\n",
    "\n",
    "    def save_model(self):\n",
    "        checkpoint = {\n",
    "            'epochs': self.epochs,\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'losses_coord': self.losses_c,\n",
    "            'losses_total': self.losses_t,\n",
    "            'accuracies': self.accuracies,\n",
    "        }\n",
    "        torch.save(checkpoint, pre_model_path)\n",
    "        # if self.epochs[-1] % 50 == 0:\n",
    "        #     torch.save(checkpoint, pre_model_path[:-3]+f'_{self.epochs[-1]}l{NUM_EPOCHS}.pt')\n",
    "        print(f\"****** Model checkpoint saved at epochs {self.epochs[-1]} ******\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907adef6",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuner(object):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.epochs = [0]\n",
    "        self.losses = [0]\n",
    "        self.accuracies = [0]\n",
    "\n",
    "    def process(self, load=False, reload=False):\n",
    "        self.build_model(load)\n",
    "        self.finetune_model(reload)\n",
    "        self.save_model()\n",
    "\n",
    "    def build_model(self, load):\n",
    "        self.model = facebook_vit.__dict__['vit_base_patch16'](\n",
    "            num_classes=1000,\n",
    "            drop_path_rate=0.1,\n",
    "            global_pool=True,\n",
    "        )\n",
    "        print(f'Parameter: {sum(p.numel() for p in self.model.parameters() if p.requires_grad)}')\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=0)\n",
    "        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "        if load:\n",
    "            checkpoint = torch.load(fine_load_model_path, map_location=device)\n",
    "            checkpoint_model = checkpoint['model']\n",
    "            for key in list(checkpoint_model.keys()):\n",
    "                if key.startswith('vit_features.'):\n",
    "                    new_key = key.replace('vit_features.', '')\n",
    "                    checkpoint_model[new_key] = checkpoint_model.pop(key)\n",
    "            for key in list(checkpoint_model.keys()):\n",
    "                if key.startswith('norm.'):\n",
    "                    new_key = key.replace('norm.', 'fc_norm.')\n",
    "                    checkpoint_model[new_key] = checkpoint_model.pop(key)\n",
    "\n",
    "            state_dict = self.model.state_dict()\n",
    "            for k in ['head.weight', 'head.bias']:\n",
    "                if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "                    print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "                    del checkpoint_model[k]\n",
    "            interpolate_pos_embed(self.model, checkpoint_model)\n",
    "            msg = self.model.load_state_dict(checkpoint_model, strict=False)\n",
    "            print(msg)\n",
    "            trunc_normal_(self.model.head.weight, std=2e-5)\n",
    "            self.model.to(device)\n",
    "\n",
    "            if 'given' not in str(fine_load_model_path):\n",
    "                self.epochs = checkpoint['epochs']\n",
    "            print(f'Parameter: {sum(p.numel() for p in self.model.parameters() if p.requires_grad)}')\n",
    "            print(f'Epoch: {self.epochs[-1]}')\n",
    "            print(f'****** Reset epochs and losses ******')\n",
    "            self.epochs = []\n",
    "            self.losses = []\n",
    "            self.accuracies = []\n",
    "\n",
    "    def finetune_model(self, reload):\n",
    "        model = self.model.train()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        if AUGMENTATION:\n",
    "            criterion = SoftTargetCrossEntropy()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "        range_epochs = range(NUM_EPOCHS)\n",
    "        if reload:\n",
    "            checkpoint = torch.load(fine_reload_model_path)\n",
    "            self.model.load_state_dict(checkpoint['model'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "            self.epochs = checkpoint['epochs']\n",
    "            self.losses = checkpoint['losses']\n",
    "            self.accuracies = checkpoint['accuracies']\n",
    "            range_epochs = range(self.epochs[-1], NUM_EPOCHS)\n",
    "\n",
    "        for epoch in range_epochs:\n",
    "            if epoch < WARMUP_EPOCHS:\n",
    "                lr_warmup = ((epoch + 1) / WARMUP_EPOCHS) * LEARNING_RATE\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr_warmup\n",
    "                if epoch + 1 == WARMUP_EPOCHS:\n",
    "                    scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "            print(f\"epoch {epoch + 1} learning rate : {optimizer.param_groups[0]['lr']}\")\n",
    "            running_loss = 0.0\n",
    "            saving_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i, data in tqdm(enumerate(train_loader, 0), total=len(train_loader)):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                if AUGMENTATION:\n",
    "                    inputs, labels = mixup_fn(inputs, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                saving_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                if not AUGMENTATION:\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "                inter = 100\n",
    "                if i % inter == inter - 1:\n",
    "                    if AUGMENTATION:\n",
    "                        print(f'[Epoch {epoch}, Batch {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "                    else:\n",
    "                        print(f'[Epoch {epoch}, Batch {i + 1:5d}] loss: {running_loss / 100:.3f}, acc: {correct / total * 100:.2f} %')\n",
    "                        self.accuracies.append(correct / total * 100)\n",
    "                    self.epochs.append(epoch + 1)\n",
    "                    self.losses.append(saving_loss / inter)\n",
    "                    running_loss = 0.0\n",
    "                    saving_loss = 0.0\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                mid_term = len(train_loader)//3\n",
    "                if i % mid_term == mid_term-1:\n",
    "                    self.val_model(epoch)\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "            self.scheduler = scheduler\n",
    "            self.save_model()\n",
    "            self.val_model(epoch)\n",
    "            scheduler.step()\n",
    "        print('****** Finished Fine-tuning ******')\n",
    "\n",
    "    def val_model(self, epoch=-1):\n",
    "        self.model.eval()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in tqdm(enumerate(val_loader, 0), total=len(val_loader)):\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = self.model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f'[Epoch {epoch + 1}] Accuracy of {len(val_dataset)} test images: {100 * correct / total:.2f} %')\n",
    "\n",
    "    def save_model(self):\n",
    "        checkpoint = {\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'scheduler': self.scheduler.state_dict(),\n",
    "            'epochs': self.epochs,\n",
    "            'losses': self.losses,\n",
    "            'accuracies': self.accuracies,\n",
    "        }\n",
    "        torch.save(checkpoint, fine_model_path)\n",
    "        #         torch.save(checkpoint, dynamic_model_path+str(self.epochs[-1])+f'_lr{LEARNING_RATE}.pt')\n",
    "        print(f\"****** Model checkpoint saved at epochs {self.epochs[-1]} ******\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0dfe1b",
   "metadata": {},
   "source": [
    "## Linear Probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProber(object):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.epochs = [0]\n",
    "        self.losses = [0]\n",
    "        self.accuracies = [0]\n",
    "\n",
    "    def process(self, load=False, reload=False):\n",
    "        self.build_model(load)\n",
    "        self.linearprob_model(reload)\n",
    "        self.save_model()\n",
    "\n",
    "    def build_model(self, load):\n",
    "        self.model = facebook_vit.__dict__['vit_base_patch16'](\n",
    "            num_classes=1000,\n",
    "            drop_path_rate=0.1,\n",
    "            global_pool=True,\n",
    "        )\n",
    "        print(f'Parameter: {sum(p.numel() for p in self.model.parameters() if p.requires_grad)}')\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=0)\n",
    "        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "        if load:\n",
    "            checkpoint = torch.load(fine_load_model_path, map_location=device)\n",
    "            checkpoint_model = checkpoint['model']\n",
    "            for key in list(checkpoint_model.keys()):\n",
    "                if key.startswith('vit_features.'):\n",
    "                    new_key = key.replace('vit_features.', '')\n",
    "                    checkpoint_model[new_key] = checkpoint_model.pop(key)\n",
    "            for key in list(checkpoint_model.keys()):\n",
    "                if key.startswith('norm.'):\n",
    "                    new_key = key.replace('norm.', 'fc_norm.')\n",
    "                    checkpoint_model[new_key] = checkpoint_model.pop(key)\n",
    "\n",
    "\n",
    "            state_dict = self.model.state_dict()\n",
    "            for k in ['head.weight', 'head.bias']:\n",
    "                if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "                    print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "                    del checkpoint_model[k]\n",
    "            interpolate_pos_embed(self.model, checkpoint_model)\n",
    "            msg = self.model.load_state_dict(checkpoint_model, strict=False)\n",
    "            print(msg)\n",
    "            trunc_normal_(self.model.head.weight, std=2e-5)\n",
    "            for _, p in self.model.named_parameters():\n",
    "                p.requires_grad = False\n",
    "            for _, p in self.model.head.named_parameters():\n",
    "                p.requires_grad = True\n",
    "            self.model.to(device)\n",
    "\n",
    "            if 'given' not in str(fine_load_model_path):\n",
    "                self.epochs = checkpoint['epochs']\n",
    "            print(f'Parameter: {sum(p.numel() for p in self.model.parameters() if p.requires_grad)}')\n",
    "            print(f'Epoch: {self.epochs[-1]}')\n",
    "            print(f'****** Reset epochs and losses ******')\n",
    "            self.epochs = []\n",
    "            self.losses = []\n",
    "            self.accuracies = []\n",
    "\n",
    "    def linearprob_model(self, reload):\n",
    "        model = self.model.train()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=0)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "        range_epochs = range(NUM_EPOCHS)\n",
    "        if reload:\n",
    "            checkpoint = torch.load(fine_reload_model_path)\n",
    "            self.model.load_state_dict(checkpoint['model'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "            self.epochs = checkpoint['epochs']\n",
    "            self.losses = checkpoint['losses']\n",
    "            self.accuracies = checkpoint['accuracies']\n",
    "            range_epochs = range(self.epochs[-1], NUM_EPOCHS)\n",
    "\n",
    "        for epoch in range_epochs:\n",
    "            if epoch < WARMUP_EPOCHS:\n",
    "                lr_warmup = ((epoch + 1) / WARMUP_EPOCHS) * LEARNING_RATE\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr_warmup\n",
    "                if epoch + 1 == WARMUP_EPOCHS:\n",
    "                    scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "            print(f\"epoch {epoch + 1} learning rate : {optimizer.param_groups[0]['lr']}\")\n",
    "            running_loss = 0.0\n",
    "            saving_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i, data in tqdm(enumerate(train_loader, 0), total=len(train_loader)):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                saving_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                inter = 100\n",
    "                if i % inter == inter - 1:\n",
    "                    print(f'[Epoch {epoch}, Batch {i + 1:5d}] loss: {running_loss / 100:.3f}, acc: {correct / total * 100:.2f} %')\n",
    "                    self.accuracies.append(correct/total*100)\n",
    "                    self.epochs.append(epoch + 1)\n",
    "                    self.losses.append(saving_loss/inter)\n",
    "                    running_loss = 0.0\n",
    "                    saving_loss = 0.0\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                mid_term = len(train_loader)//3\n",
    "                if i % mid_term == mid_term-1:\n",
    "                    self.val_model(epoch)\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "            self.scheduler = scheduler\n",
    "            self.save_model()\n",
    "            self.val_model(epoch)\n",
    "            scheduler.step()\n",
    "        print('****** Finished Fine-tuning ******')\n",
    "\n",
    "    def val_model(self, epoch=-1):\n",
    "        self.model.eval()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in tqdm(enumerate(val_loader, 0), total=len(val_loader)):\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = self.model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f'[Epoch {epoch + 1}] Accuracy of {len(val_dataset)} test images: {100 * correct / total:.2f}%')\n",
    "\n",
    "    def save_model(self):\n",
    "        checkpoint = {\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'scheduler': self.scheduler.state_dict(),\n",
    "            'epochs': self.epochs,\n",
    "            'losses': self.losses,\n",
    "            'accuracies': self.accuracies,\n",
    "        }\n",
    "        torch.save(checkpoint, fine_model_path)\n",
    "        #         torch.save(checkpoint, dynamic_model_path+str(self.epochs[-1])+f'_lr{LEARNING_RATE}.pt')\n",
    "        print(f\"****** Model checkpoint saved at epochs {self.epochs[-1]} ******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d96e0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T06:27:49.483718Z",
     "start_time": "2024-04-17T06:27:21.298578Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    trainer = PreTrainer()\n",
    "    trainer.process(load=False)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     trainer = FineTuner()\n",
    "#     trainer.process(load=True)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     trainer = LinearProber()\n",
    "#     trainer.process(load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Pre-training]\n",
    "epochs 3에서 사전 테스트\n",
    "-> c=sL1, batch_size=64, lr=6e-06 : 11.31%\n",
    "-> c=sL1, batch_size=64, lr=7e-06 : 11.32%\n",
    "-> c=sL1, batch_size=64, lr=8e-06 : 11.32%\n",
    "-> c=sL1, batch_size=64, lr=9e-06 : 11.36%\n",
    "-> c=sL1, batch_size=64, lr=1e-05 : 11.36% (best)\n",
    "-> c=sL1, batch_size=64, lr=2e-05 : 11.29%\n",
    "-> c=sL1, batch_size=64, lr=3e-05 : 11.30%\n",
    "\n",
    "-> c=sL1, batch_size=64, lr=1e-05, ratio=7e03 : 11.37%\n",
    "-> c=sL1, batch_size=64, lr=1e-05, ratio=1e04 : 11.68% (best) ->  50 epochs, X(학습 불안정)\n",
    "-> c=sL1, batch_size=64, lr=1e-05, ratio=3e04 : 11.39%\n",
    "-> c=sL1, batch_size=64, lr=1e-05, ratio=1e05 : 11.36% -> 50 epochs, 75.8%-> 100 epochs, 95.4%\n",
    "-> c=sL1, batch_size=64, lr=1e-05, ratio=3e05 : 11.38%\n",
    "\n",
    "[Fine-tuning]\n",
    "epochs 2에서 사전 테스트, (pre 84 epochs)\n",
    "-> batch_size=64, lr=2e-01 : 19.70%\n",
    "-> batch_size=64, lr=1e-01 : 20.22%\n",
    "-> batch_size=64, lr=7e-02 : 23.13%\n",
    "-> batch_size=64, lr=5e-02 : 23.88%\n",
    "-> batch_size=64, lr=4e-02 : 25.87% (best) -> 50 epochs X, 100 epochs O\n",
    "-> batch_size=64, lr=3e-02 : 22.55%\n",
    "-> batch_size=64, lr=3e-02 : 22.55%\n",
    "\n",
    "-> batch_size=32, lr=9e-03 : 18.06%\n",
    "-> batch_size=32, lr=1e-02 : 18.98%\n",
    "-> batch_size=32, lr=2e-02 : 23.02% (best) -> 100 epochs, (진행중)\n",
    "-> batch_size=32, lr=3e-02 : 22.01%\n",
    "-> batch_size=32, lr=4e-02 : 22.12%\n",
    "\n",
    "[Linear-probing]\n",
    "epochs 2에서 사전 테스트, LARS\n",
    "-> batch_size=256, lr=8 : 8.48%\n",
    "-> batch_size=256, lr=7 : 8.70%\n",
    "-> batch_size=256, lr=6 : 11.23%\n",
    "-> batch_size=256, lr=5 : 12.40% (best) -> 100 epochs, 발산 -> warm up 제거, 발산\n",
    "-> batch_size=256, lr=4 : 12.00%\n",
    "-> batch_size=256, lr=3 : 11.62%\n",
    "-> batch_size=32, lr=5e-01 : 12.54% (best) -> 100 epochs, 발산\n",
    "-> batch_size=32, lr=4e-01 : 8.55%\n",
    "-> batch_size=32, lr=2e-01 : 9.14%\n",
    "-> batch_size=32, lr=1e-01 : 6.98%\n",
    "\n",
    "epochs 2에서 사전 테스트, SGD\n",
    "-> batch_size=32, lr=3e-02 : 8.16%\n",
    "-> batch_size=32, lr=2e-02 : 10.84%\n",
    "-> batch_size=32, lr=1e-02 : 12.94%\n",
    "-> batch_size=32, lr=9e-03 : 14.62%\n",
    "-> batch_size=32, lr=8e-03 : 16.46% (best) -> 100 epochs, 정체\n",
    "-> batch_size=32, lr=7e-03 : 15.00%\n",
    "-> batch_size=32, lr=6e-03 : 14.45%\n",
    "-> batch_size=32, lr=5e-03 : 12.62%\n",
    "-> batch_size=32, lr=4e-03 : 13.67%\n",
    "-> batch_size=32, lr=3e-03 : 13.34%\n",
    "\n",
    "epochs 2에서 사전 테스트, SGD, 아키텍처 fine 이랑 동일하게 수정\n",
    "-> batch_size=32, lr=8e-02 : 13.91%\n",
    "-> batch_size=32, lr=7e-02 : 13.12%\n",
    "-> batch_size=32, lr=6e-02 : 15.66%\n",
    "-> batch_size=32, lr=5e-02 : 19.67% (best) -> 100 epochs, 초반 불안정 -> warm up 제거, -> 50 epochs, \n",
    "-> batch_size=32, lr=4e-02 : 17.91% -> 50 epochs, \n",
    "-> batch_size=32, lr=3e-02 : 13.22%\n",
    "-> batch_size=32, lr=2e-02 : 13.32%\n",
    "-> batch_size=32, lr=1e-02 : 15.11%\n",
    "-> batch_size=32, lr=9e-03 : 13.34%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Ablation study]\n",
    "loss_same 제거: \n",
    "MSE: \n",
    "+)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
